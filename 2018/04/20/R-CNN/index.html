<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="专注于机器学习、深度学习、图形图像处理。"><title>R-CNN | 噢噢噢噢奥利</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">R-CNN</h1><a id="logo" href="/.">噢噢噢噢奥利</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Start</i></a><a href="/archives/"><i class="fa fa-archive"> Archiv</i></a><a href="/about/"><i class="fa fa-user"> Über</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">R-CNN</h1><div class="post-content"><p>&emsp;&emsp;Region proposals with CNNs(R-CNN)用分类的方法解决目标检测的问题。和之前的方法相比，R-CNN把mAP提高了30%多。</p>
<a id="more"></a>
<h1 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h1><p>&emsp;&emsp;R-CNN模型分为4个步骤：</p>
<ol>
<li><p>生成候选区域：一张原始图片生成约2000个候选区，文章采用的是Selective Search方法。</p>
</li>
<li><p>特征提取：把候选区域缩放到固定尺寸送入CNN做特征提取。固定尺寸取决于使用的网络模型，文章中用的是AlexNet，故缩放到227×227。</p>
</li>
<li><p>分类器：把提取的特征送入SVMs进行分类，判别属于哪个类别。</p>
</li>
<li><p>回归器：使用回归器修正候选框的四个参数。</p>
</li>
</ol>
<p><img src="https://i.loli.net/2018/05/07/5aefbf7e071cc.png" alt="图1：R-CNN基本流程"></p>
<h1 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h1><h2 id="1-有监督预训练"><a href="#1-有监督预训练" class="headerlink" title="1. 有监督预训练"></a>1. 有监督预训练</h2><p>&emsp;&emsp;在数据量大的辅助数据集上（ILSVRC 2012）训练CNN网络，仅仅用分类标签训练。ILSVRC 2012数据集包含1000个类别的样本。</p>
<h2 id="2-fine-tuning-微调"><a href="#2-fine-tuning-微调" class="headerlink" title="2. fine-tuning 微调"></a>2. fine-tuning 微调</h2><p>&emsp;&emsp;把1中的训练结果作为CNN的初始化参数，把CNN的输出由1000个类别改为21个类别，其他结构不变，再次进行训练。21个类别是VOC的20个类加上背景类构成。</p>
<p>&emsp;&emsp;训练数据：输入是region proposal，输出是类别。对于一个region proposal，若与任何一个ground-truth的IoU&lt;=0.5，标记为正类，类别是IoU最大的ground-truth的类别；否则为负例，就是背景类。负例数量要远多于正例。</p>
<p>&emsp;&emsp;训练细节：随机梯度下降SGD；mini_batch = 128，其中32个正例（包含所有类别），96个背景类；步长为0.001。每个batch都偏向正例，提高了正例的比例。</p>
<h2 id="3-分类器"><a href="#3-分类器" class="headerlink" title="3. 分类器"></a>3. 分类器</h2><p>&emsp;&emsp;R-CNN又单独训练了SVMs分类器，没有直接采用2中的FC+softmax+cross entropy，并且样本正负例的划分也不同。对于一个候选框，当IoU&lt;0.3时标记为负例（0.3这个值是在{0,0.1,…,0.5}六个阈值上做交叉验证得到的）；只有ground truth被标记为正例。对于每个类别训练一个SVM分类器，由于训练数据太多，内存不够，文章采用了hard negative mining method。</p>
<p><u>如何做hard negative mining（困难样本挖掘）？</u><br>&emsp;&emsp;hard negative：就是false positive的样本，候选框标记为负例，预测为正例的样本。比如：一个候选框标记为背景类，但候选框中可能有一半包含了object，此时模型可能对这个框false positive，即把它预测为正例。<br>&emsp;&emsp;easy negative:候选框全是背景，模型就很容易把这样的框正确识别为背景类。<br>&emsp;&emsp;对于目标检测来说，大量的候选框为背景类，较少的框为目标类别，目标类别比较容易辨别（目标类的框IoU=1，因为只有ground truth被标记为正例），IoU接近0的背景类也容易，但是IoU不接近0的背景类容易被预测为某个目标类别，所以要重点关注。<br>&emsp;&emsp;hard negative mining方法就是在迭代中重点关注了false positive：进行一轮训练，用此时的模型对负例（背景类）进行预测，把被预测为正例的样本加入训练集合；进行新一轮的训练和关注。</p>
<p><u>为什么不直接采用fine-tuned CNN中的输出，而是又训练一个分类器？为什么在fine-tuning和SVM training阶段，正负例的划分标准不同？</u><br>&emsp;&emsp;作者尝试使用FC8的输出进行非极大值抑制，发现效果不如当前方法好。原因在于：训练CNN时，IoU&gt;0.5就被标记为正例，这个条件对于分类器来说过于宽松，所以CNN不能实现精确定位；但是若把条件提高，比如阈值提高，则会减少正例的数量，不适合深度学习的训练。因此进行hard positive mining的SVM训练。训练支持向量机时，IoU=1为正例，IoU&lt;0.3为负例，样本量减少，SVM适合小样本的分类问题。</p>
<h2 id="4-回归器"><a href="#4-回归器" class="headerlink" title="4.回归器"></a>4.回归器</h2><p>&emsp;&emsp;文章在误差分析中提到了 bounding box regression，精修之后mAP提高了3到4个百分点。</p>
<p><u>如何做bounding box regression？</u></p>
<blockquote>
<p><a href="https://zixianzheng.github.io/2018/04/24/Bounding-box%20Regression/" target="_blank" rel="noopener">https://zixianzheng.github.io/2018/04/24/Bounding-box%20Regression/</a></p>
</blockquote>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>&emsp;&emsp;按照开头提到的流程：SS提取候选框，缩放到227*227，送入CNN提取特征（AlexNet最后一个全连接层的输出reshape为4096-d的向量），最后分别送入分类器和回归器。</p>
<ol>
<li><p>分类器输入候选框的特征向量，得到某个候选框在K=20个类别上的打分；对于2000个候选框，得到2000×20的矩阵。</p>
</li>
<li><p>在矩阵的每一列上做贪婪的非极大值抑制（non-maximum suppression,NMS），即在每个类别上执行NMS，目的是去除相交的多余候选框。</p>
<p><u>如何做non-maximum suppression？</u><br>&emsp;&emsp;1.每一列2000个分值，按照将序排列。<br>&emsp;&emsp;2.选中得分最高的框，遍历剩下所有的框，若IoU大于某个阈值，则删除该框。<br>&emsp;&emsp;3.在剩下的proposals中，执行2，直到所有的proposals都被选中。</p>
</li>
<li><p>最后把分值小于某个阈值的的候选框剔除（文章没有提到，应该是这样），最终得到的候选框即为R-CNN检测的目标。（先剔除，再NMS应该也可以。）</p>
</li>
</ol>
</div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://github.com/zixianzheng.github.io.git"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Kategorien</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux相关/">Linux相关</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/图形图像处理/">图形图像处理</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/R-CNN/" style="font-size: 15px;">R-CNN</a> <a href="/tags/object-detection/" style="font-size: 15px;">object detection</a> <a href="/tags/obejct-detection/" style="font-size: 15px;">obejct detection</a> <a href="/tags/Ubuntu14-04/" style="font-size: 15px;">Ubuntu14.04</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/GPU/" style="font-size: 15px;">GPU</a> <a href="/tags/Anaconda/" style="font-size: 15px;">Anaconda</a> <a href="/tags/DeepLearning/" style="font-size: 15px;">DeepLearning</a> <a href="/tags/VGG/" style="font-size: 15px;">VGG</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Letzte</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/05/17/SSD/">SSD</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/02/YOLO/">YOLO</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/29/Faster R-CNN/">Faster R-CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/27/Fast R-CNN/">Fast R-CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/26/Ubuntu14.04下，Anaconda安装Tensorflow1.4.0-GPU/">Ubuntu14.04下，Anaconda安装Tensorflow1.4.0-GPU</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/25/常用Linux命令/">常用Linux命令</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/20/Bounding-box Regression/">Bounding-box Regression</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/20/R-CNN/">R-CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/15/VGGNet/">VGGNet</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div><ul></ul><a href="https://github.com/zixianZheng" title="github" target="_blank">github</a><ul></ul><a href="https://weibo.com/u/3700586755" title="weibo" target="_blank">weibo</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">噢噢噢噢奥利.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>
<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="专注于机器学习、深度学习、图形图像处理。"><title>VGGNet | 噢噢噢噢奥利</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">VGGNet</h1><a id="logo" href="/.">噢噢噢噢奥利</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Start</i></a><a href="/archives/"><i class="fa fa-archive"> Archiv</i></a><a href="/about/"><i class="fa fa-user"> Über</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">VGGNet</h1><div class="post-content"><p>&emsp;&emsp;这篇文章主要论述了CNN的<strong>深度</strong>对网络性能的影响。VGGNet在2014年的ImageNet的比赛中，定位第一，分类第二。</p>
<a id="more"></a>
<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>对于AlexNet的提升：</p>
<ul>
<li>第一个卷积层使用更小的卷积核、更小的滑动步长</li>
<li>训练和测试时，使用 $multiple-scales$</li>
<li>增加网络的深度</li>
</ul>
<h2 id="2-网络配置"><a href="#2-网络配置" class="headerlink" title="2. 网络配置"></a>2. 网络配置</h2><h3 id="2-1-配置"><a href="#2-1-配置" class="headerlink" title="2.1 配置"></a>2.1 配置</h3><p>预处理：每个像素点做<strong>归一化</strong>处理。<br>输$\ \ \ $入：训练时使用 $224\times 224 \ RGB$ 图片。<br>卷积核：全部使用$size = 3\times 3, stride = 1, padding = 1 \ (padding = “SAME”)$，<br>                $\qquad  \quad \ 3\times 3$ 是最小的能够捕获上下左右中的特征的尺寸。<br>                $\qquad  \quad \ $只有 $C$ 网络使用了 $1\times 1$的卷积核。<br>池$\ \ \ $化：$ \ size = 2\times 2, stride = 2,$ 5个池化层。<br>全连接：$4096-4096-1000-Softmax$<br>激活函数： $ReLU$<br>LRN: 只有 A_LRN 网络使用了局部响应归一化；<br>$\quad  \quad $在ILSVRC数据集中，LRN并没有提升模型性能。</p>
<h3 id="2-2-结构"><a href="#2-2-结构" class="headerlink" title="2.2 结构"></a>2.2 结构</h3><p>5个池化层，5阶段卷积特征提取。<br><img src="./1515488075521.png" alt="Alt text"></p>
<h3 id="2-3-讨论"><a href="#2-3-讨论" class="headerlink" title="2.3 讨论"></a>2.3 讨论</h3><ul>
<li>两层的$3\times 3$卷积核的有效感受野是$5\times 5$</li>
<li>三层的$3\times 3$卷积核的有效感受野是$7\times 7$</li>
<li>大卷积核的浅层网络  和 小卷积核的深层网络？（3层3×3  和  1层7×7）<ul>
<li>包含了更多层的非线性层，使得决策函数更具有判别性。</li>
<li>减少了参数量。假设输入输出都是 C 个通道，三层3×3有 $3(9C^2)=27C^2$个参数，一层7×7有$7^2C^2=49C^2$个参数。</li>
<li>所以可以把三个3×3的filter看成是一个7×7filter的分解（中间层有非线性的分解）。</li>
</ul>
</li>
<li>1×1 filter 保持输入输出维度不变的条件下，先进行线性映射（卷积核），再进行非线性处理（ReLU）。</li>
</ul>
<h2 id="3-分类框架"><a href="#3-分类框架" class="headerlink" title="3. 分类框架"></a>3. 分类框架</h2><h3 id="3-1-训练"><a href="#3-1-训练" class="headerlink" title="3.1 训练"></a>3.1 训练</h3><ul>
<li>SGD 优化 Softmax+Entropy ：<ul>
<li>参数：<br>$mini-batch = 256$<br>$momentum=0.9$<br>$weight-decay = 5\cdot  10^{-4}(L_2正则化)$<br>$dropout-ratio=0.5(FC的前两层)$<br>$learning-rate=10^{-2}(测试误差不再降低时，除以10，共减少三次)$</li>
<li>VGG 收敛更快，可能因为：更深度的网络和小的卷积核起到了隐性的正则化作用；一些层的初始化pre_initialisation。</li>
</ul>
</li>
<li>参数初始化： <ul>
<li>A 网络随机初始化，然后训练。</li>
<li>B-E 网络，前四个卷积层（？？？）和最后三个全连接层使用A网络训练好的参数初始化，其他参数随机初始化。</li>
<li>随机初始化时，权重从正态分布$ N(0, 0.01)$ 中采样，偏置为 0。</li>
</ul>
</li>
<li>如何获得 224×224 input images ？：<br>$\quad \ \ $记S为缩放后的图片的小边长度，S&gt;224，在缩放后的图片中提取 224×224 的片段进行训练。<ul>
<li>方法一（固定S）：在 S = 256 和 S = 384 两个尺度上训练两个模型，再模型融合（求平均）。</li>
<li>方法二（multi-scale training）：在区间$[S_{min},S_{max}]$上，随机选取一个scale，把图片缩放到该尺度，再随机提取 224×224 片段，训练一个网络。该方法可以看做训练集合的数据增强：<strong>Scale jittering</strong>，即用多尺度的图片训练同一个模型。</li>
</ul>
</li>
</ul>
<h3 id="3-2-测试"><a href="#3-2-测试" class="headerlink" title="3.2 测试"></a>3.2 测试</h3><ul>
<li>记Q为测试图片缩放后的小边长度，不要求Q = S （对于每个S，使用多个Q值可以提升性能）。</li>
<li>dense evaluation:<ul>
<li>把FC层的每个神经元看成 1×1 的卷积核，直接输入缩放后的图片，不需要提取 224*224 的图片。</li>
<li>网络输出 class score map，取平均值。</li>
<li>最终的分值 由缩放后的图片和其水平翻转的图片 取均值 决定。</li>
</ul>
</li>
<li>multi-crop evaluation:<br>$\qquad $AlexNet 中的做法：一张测试图片，提取四个角和中间的 224*224 图片，和水平翻转的图片共10张，分别送入网络，10个分值取均值。</li>
<li>两种方法是互补的，原因在于不同的卷积边界条件<br>  （convolution boundary conditions）：<ul>
<li>multi-crop 中特征图用 0 值填充。10张图片比dense evalution的计算量更大。</li>
<li>dense 中特征图用 图片本身周围的像素值填充，增加了全局的 接受域，捕捉了更多的内容。</li>
</ul>
</li>
</ul>
<h2 id="4-分类实验"><a href="#4-分类实验" class="headerlink" title="4. 分类实验"></a>4. 分类实验</h2><h3 id="4-1-Single-Scale-Evaluation"><a href="#4-1-Single-Scale-Evaluation" class="headerlink" title="4.1 Single Scale Evaluation"></a>4.1 Single Scale Evaluation</h3><p><img src="./1515486609340.png" alt="Alt text"></p>
<ul>
<li>ABCDE：网络越深，性能越好。</li>
<li>A 与 A-LRN：局部响应归一化没有作用。</li>
<li>B 与 C：增加的 1*1 filter 增加了 非线性能力，性能更好。</li>
<li>C 与 D：3×3的卷积核 比 1×1 的更好，3×3的filter 能捕捉空间上的特征。</li>
<li>文章也测试了 小核的深度网络 比 大核的浅层网络 性能更好（同样的有效接受域）。</li>
</ul>
<h3 id="4-2-Multi-Scale-Evaluation"><a href="#4-2-Multi-Scale-Evaluation" class="headerlink" title="4.2 Multi-Scale Evaluation"></a>4.2 Multi-Scale Evaluation</h3><ul>
<li>方法一：训练时固定$S$，测试时 $Q =  { S-32, S, S+32} $</li>
<li>方法二：训练时用 $Scale\ Jittering, S\in [S_{min},S_{max}]$，测试时$Q = { S_{min}, \frac{S_{min}+S_{max}}{2},S_{max} } $</li>
<li>multi-scale training 加 multi-scale test 效果更好。<br><img src="./1515487949968.png" alt="Alt text"></li>
</ul>
<h3 id="4-3-Multi-Crop-Evaluation"><a href="#4-3-Multi-Crop-Evaluation" class="headerlink" title="4.3 Multi-Crop Evaluation"></a>4.3 Multi-Crop Evaluation</h3><p><img src="./1515488220270.png" alt="Alt text"><br>和dense evaluation相比，multiple crops效果稍微好一点，两者一起使用效果更好。</p>
<h3 id="4-4-模型融合"><a href="#4-4-模型融合" class="headerlink" title="4.4 模型融合"></a>4.4 模型融合</h3><p><img src="./1515488404028.png" alt="Alt text"><br>D、E两个模型融合的效果比7个模型融合的效果更好。（？？）</p>
</div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://github.com/zixianzheng.github.io.git"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Kategorien</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux相关/">Linux相关</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/图形图像处理/">图形图像处理</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/R-CNN/" style="font-size: 15px;">R-CNN</a> <a href="/tags/obejct-detection/" style="font-size: 15px;">obejct detection</a> <a href="/tags/Faster-R-CNN/" style="font-size: 15px;">Faster R-CNN</a> <a href="/tags/Ubuntu14-04/" style="font-size: 15px;">Ubuntu14.04</a> <a href="/tags/object-detection/" style="font-size: 15px;">object detection</a> <a href="/tags/GPU/" style="font-size: 15px;">GPU</a> <a href="/tags/Anaconda/" style="font-size: 15px;">Anaconda</a> <a href="/tags/DeepLearning/" style="font-size: 15px;">DeepLearning</a> <a href="/tags/VGG/" style="font-size: 15px;">VGG</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Letzte</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/04/29/Faster R-CNN/">Faster R-CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/27/Fast R-CNN/">Fast R-CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/26/Ubuntu14.04下，Anaconda安装Tensorflow1.4.0-GPU/">Ubuntu14.04下，Anaconda安装Tensorflow1.4.0-GPU</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/25/常用Linux命令/">常用Linux命令</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/24/Bounding-box Regression/">Bounding-box Regression</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/20/R-CNN/">R-CNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/15/VGGNet/">VGGNet</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div><ul></ul><a href="https://github.com/zixianZheng" title="github" target="_blank">github</a><ul></ul><a href="https://weibo.com/u/3700586755" title="weibo" target="_blank">weibo</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">噢噢噢噢奥利.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>